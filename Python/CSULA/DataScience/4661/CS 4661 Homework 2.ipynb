{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a- Read\tthe\tiris\tdataset\tfrom\tthe\tfollowing\tURL:\t\n",
    "'https://raw.githubusercontent.com/mpourhoma/CS4661/master/iris.csv'\t\t\t\n",
    "and\tassign\tit\tto\ta\tPandas\tDataFrame\tas\tyou\tlearned\tin\ttutorial\tLab2-3.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score \n",
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "iris_df = pd.read_csv('https://raw.githubusercontent.com/mpourhoma/CS4661/master/iris.csv')\n",
    "\n",
    "def categorical_to_numeric(x):\n",
    "    if x == 'setosa':\n",
    "        return 0\n",
    "    elif x == 'versicolor':\n",
    "        return 1\n",
    "    elif x == 'virginica':\n",
    "        return 2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b- Split\t the\t dataset\t into\t testing\t and\t training\t sets\t with\t the\t following\t parameters:\t\n",
    "test_size=0.4,\trandom_state=1\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X= iris.data\n",
    "y=iris.target\n",
    "X_train, X_test,y_train,y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c- Instantiate\ta\tKNN\tobject\twith\tK=3,\ttrain\tit\ton\tthe\ttraining\tset\tand\ttest\tit\ton\tthe\ttesting\tset.\t\n",
    "Then,\tcalculate\tthe\taccuracy\tof\tyour\tprediction\tas\tyou\tlearned\tin\tLab3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.983333333333\n"
     ]
    }
   ],
   "source": [
    "K=3\n",
    "knn = KNeighborsClassifier(n_neighbors=K)\n",
    "knn.fit(X_train, y_train)\n",
    "y_predict = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d- Repeat\tpart\t(c)\t\tfor\tK=1,\tK=5,\tK=7,\tK=15,\tK=28,\tK=60\t(you\tcan\tsimply\twrite\ta\t“for\tloop”\ton\t\n",
    "a\tlist\twith\tthese\tvalues\tto\trepeat\tthe\tprocess\tfor\tyou,\tand\tsave\tthe\tfinal\taccuracy\tresults\t\n",
    "in\ta\tlist\t(array)!).\tDoes\tthe\taccuracy\talways\tget\tbetter\tby\tincreasing\tK?\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666666666666667, 0.98333333333333328, 0.98333333333333328, 0.98333333333333328, 0.94999999999999996, 0.80000000000000004]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test,y_train,y_test = train_test_split(X, y, test_size=0.4, random_state=1)    \n",
    "kList = [1, 5, 7, 15, 28, 60]\n",
    "accuracyList=[]\n",
    "for k in kList:\n",
    "    knn= KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_predict = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    accuracyList.append(accuracy)\n",
    "    \n",
    "print(accuracyList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the accuracy always get better by increasing K? \n",
    "\n",
    "### It does not look like it's getting better when K=60 its 0.80000000000000004 and  K = 5 is 0.98333333333333328"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e- Now,\tsuppose\tthat\twe\twould\tlike\tto\tmake\tprediction\tbased\ton\tonly\tONE\tsingle\tfeature.\t\n",
    "To\tfind\tthe\tbest\tsingle\tfeature,\twe\thave\tto\ttry\tevery\tfeature\tindividually.\tIn\tother\tword,\t\n",
    "we\t have\t to\t repeat\t part\t (c)\t 4\t times\t (each\t time\t using\t only\t one\t of\t the\t 4\t features),\t and\t\n",
    "compute\tthe\taccuracy\teach\ttime.\tThen,\tcheck\tthe\taccuracies.\tWhich\tindividual\tfeature\t\n",
    "provide\t the\t best\t accuracy\t (the\t best\t feature)?\t \t Which\t one\t is\t the\t second\t best\t feature?\t\n",
    "(Note:\tyou\thave\tto\ttrain,\ttest,\tand\tevaluate\tyour\tmodel\t4\ttimes,\teach\ttime\ton\ta\tdataset\t\n",
    "including\tonly\tone\tof\tthe\tfeatures.\tYou\tmay\twant\tto\twrite\ta\t“for\tloop”\tto\tgenerate\tthe\t\n",
    "datasets,\ttrain,\ttest,\tand\tcompute\tthe\taccuracy\teach\ttime,\tand\tsave\tthe\tfinal\taccuracy\t\n",
    "results\tin\ta\tlist).\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length = 0.633333333333\n",
      "sepal_width = 0.533333333333\n",
      "petal_length = 0.966666666667\n",
      "petal_width = 0.933333333333\n",
      "\n",
      "best feature is : 0.966666666667\n",
      "second best feature is : 0.933333333333\n",
      "\n",
      "[0.6333333333333333, 0.53333333333333333, 0.96666666666666667, 0.93333333333333335]\n"
     ]
    }
   ],
   "source": [
    "iris_df['label'] = iris_df['species'].apply(categorical_to_numeric)\n",
    "feature_cols = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "# iris_df[0::10]\n",
    "\n",
    "K=3\n",
    "knn = KNeighborsClassifier(n_neighbors=K)\n",
    "\n",
    "oneFeatureList=[]\n",
    "count = 0\n",
    "\n",
    "for fc in feature_cols:\n",
    "    X= iris_df[[fc]]\n",
    "    y= iris_df['label']\n",
    "    X_train, X_test,y_train,y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_predict = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    oneFeatureList.append(accuracy)\n",
    "    print feature_cols[count] + \" = \" + str(oneFeatureList[count])\n",
    "    count+=1\n",
    "    \n",
    "    \n",
    "second_best_feature = sorted(oneFeatureList)[-2]\n",
    "best_feature = sorted(oneFeatureList)[-1]\n",
    "print (\"\\nbest feature is : \" + str(best_feature))\n",
    "print (\"second best feature is : \" + str(second_best_feature) + \"\\n\")\n",
    "print (oneFeatureList)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best feature is petal_length = 0.966666666667 and second best feature is petal_width = 0.933333333333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f- Now,\twe\twant\tto\trepeat\tpart\t(e),\tthis\ttime\tusing\ttwo\tfeatures.\tyou\thave\tto\ttrain,\ttest,\tand\t\n",
    "evaluate\t your\t model\t for\t 6\t different\t cases:\t using\t (1 st \t and\t 2 nd \t features),\t (1 st \t and\t 3 rd \t\t\n",
    "features),\t(1 st \tand\t4 th \t\tfeatures),\t(2 nd \t\tand\t3 rd \t\tfeatures),\t(2 nd \tand\t4 th \tfeatures),\t(3 rd \tand\t4 th \t\t\n",
    "features)!\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "Which “feature\tpair”\tprovide\tthe\tbest\taccuracy?\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length and sepal_width is 0.65\n",
      "sepal_length and petal_length is 0.933333333333\n",
      "sepal_length and petal_width is 0.983333333333\n",
      "sepal_width and petal_length is 0.95\n",
      "sepal_width and petal_width is 0.966666666667\n",
      "petal_length and petal_width is 0.966666666667\n",
      "\n",
      "\n",
      "[0.65000000000000002, 0.93333333333333335, 0.98333333333333328, 0.94999999999999996, 0.96666666666666667, 0.96666666666666667]\n",
      "\n",
      " The best feature pair accuracy is : sepal_length and petal_width 0.983333333333\n"
     ]
    }
   ],
   "source": [
    "iris_df['label'] = iris_df['species'].apply(categorical_to_numeric)\n",
    "feature_cols=[['sepal_length','sepal_width'],['sepal_length','petal_length'],['sepal_length','petal_width'],['sepal_width','petal_length'],['sepal_width','petal_width'],['petal_length','petal_width']]\n",
    "\n",
    "K=3\n",
    "knn = KNeighborsClassifier(n_neighbors=K)\n",
    "featureList=[]\n",
    "count = 0\n",
    "best_accuracy_pair = \"\"\n",
    "best_accuracy_value = 0\n",
    "for fc in feature_cols:\n",
    "    X= iris_df[fc]\n",
    "    y= iris_df['label']\n",
    "    X_train, X_test,y_train,y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_predict = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    featureList.append(accuracy)\n",
    "    string = ' and '.join(map(str,feature_cols[count]) )\n",
    "    print (string + \" is \" + str(featureList[count]))\n",
    "\n",
    "    if featureList[count] > best_accuracy_value:\n",
    "        best_accuracy_value = featureList[count]\n",
    "        best_accuracy_pair = string\n",
    "    count += 1\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(featureList)\n",
    "print (\"\\n The best feature pair accuracy is : \" +  best_accuracy_pair + \" \" + str(best_accuracy_value)  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sepal length and petal width is the best feature pair "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g- Big\tQuestion:\tDoes\tthe\t“best\tfeature\tpair”\tfrom\tpart\t(f)\tcontain\tof\tboth\t“first\tbest\tfeature”\t\n",
    "and\t“second\tbest\tfeature”\tfrom\tpart\t(e)?\t\tIn\tother\tword,\tcan\twe\tconclude\tthat\tthe\t“best\t\n",
    "two\tfeatures”\tfor\tclassification\tare\tthe\t“first\tbest\tindividual\tfeature”\tand\tthe\t“second\tbest\t\n",
    "individual\tfeature”\ttogether?\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### No Because the best two features is petal length and petal width on part e.  But on part f, the best feature pair is sepal lenght and petal width.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h- Optional\tQuestion:\tJustify\tyour\tanswer\tto\tpart\t(g)!\t\tIf\tyes,\twhy?\t\tIf\tno,\twhy\tnot?\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### It is because more data is being analyzed as a dataframe set and what the best feature on just one part of the feature might be offset if used with another set of the feature.  The sum of the second pair could offset the value of the output as a whole.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

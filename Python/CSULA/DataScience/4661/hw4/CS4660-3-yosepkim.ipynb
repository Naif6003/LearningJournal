{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yosep Kim\n",
    "\n",
    "Do some machine learning on data found here http://mlr.cs.umass.edu/ml/machine-learning-databases/adult/using aimed at predicting whether or not a person will make over 50k a year. Do it in an IPython Notebook. Look in adult.data for the data, save it as a csv file. The adult.names file has information about the set. \n",
    "\n",
    "**DONE** 2 pts Create a notebook.\n",
    "\n",
    "**DONE** 2 pts Replace all empty numeric fields with the average of its column in this new column (if there are any, if not, you get 2 free points).\n",
    "\n",
    "**DONE** 2 pts Either:\n",
    "<hr>\n",
    "a) Replace all categorical data (data that is in categories, not numbers) with one-hot encoding (see http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) or\n",
    "\n",
    "b) Convert non-numeric columns (that is, categorical data) to columns with an integer representations (like we did with the decision trees). \n",
    "<hr>\n",
    "**DONE**\n",
    "Note: for \"?\", please find the value that is most common in the column it is found and replace the \"?\" with it.\n",
    "\n",
    "**DONE** 2 pts Convert the data to a numpy array if it isn't one already.\n",
    "\n",
    "**DONE** 2 pts Divide the data into a training and test set.\n",
    "\n",
    "**DONE** 2 pts Run both a random forest and gaussian naive bayes on the training set.\n",
    "\n",
    "**DONE**\n",
    "2 pts Compute the accuracy of predictions on the test set.\n",
    "\n",
    "**DONE**\n",
    "2pts each extra credit: Use another additional classifier.\n",
    "\n",
    "\n",
    "# [DONE] 2 pts Create a notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changed Features for dataframe as described in  adult.names for readability\n",
    "## age, workclass, fnlwgt, education, education-num, marital-status, occupation, relationship, race, sex capital-gain, capital-loss, hours-per-week: continuous, native-country\n",
    "\n",
    "## Changed '?' to NaN values to use '.fillna()' function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cowboyuniverse/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'adult.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6f8efd62462f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m            \u001b[0;34m\"marital_status\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"occupation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"relationship\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"race\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gender\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m            \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"income\"]\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m',\\s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"?\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    993\u001b[0m                                  ' \"c\", \"python\", or' ' \"python-fwf\")'.format(\n\u001b[1;32m    994\u001b[0m                                      engine=engine))\n\u001b[0;32m--> 995\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m   1983\u001b[0m         f, handles = _get_handle(f, mode, encoding=self.encoding,\n\u001b[1;32m   1984\u001b[0m                                  \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1985\u001b[0;31m                                  memory_map=self.memory_map)\n\u001b[0m\u001b[1;32m   1986\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# Python 3 and no explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'adult.data'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_data = 'adult.data'\n",
    "test_data = 'adult.test'\n",
    "features = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
    "           \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n",
    "           \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"income\"]\n",
    "train_df = pd.read_csv(train_data, header=None, names=features, sep=',\\s', na_values=[\"?\"])\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# [done] 2 pts Convert the data to a numpy array if it isn't one already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_data =  np.loadtxt('adult.data', dtype=str, delimiter=',')\n",
    "# my_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [done] 2 pts Divide the data into a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_for_X = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
    "           \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n",
    "           \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\"]\n",
    "\n",
    "X = train_df[features_for_X]\n",
    "\n",
    "y = train_df['income']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperating object and int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obj_train_df = X.select_dtypes(include=['object']).copy()\n",
    "int64_train_df = X.select_dtypes(include=['int64']).copy()\n",
    "# obj_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [DONE] 2 pts Replace all empty numeric fields with the average of its column in this new column.\n",
    "\n",
    "### There are no any empty numeric fields 'False' and putting all averages NaN values inside obj_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False\n",
    "int64_train_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for any NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_train_df[obj_train_df.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for the most common value and fill NaN with those values and filling in NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj_train_df[\"workclass\"].mode()\n",
    "# obj_train_df[\"education\"].mode()\n",
    "# obj_train_df[\"marital_status\"].mode()\n",
    "# obj_train_df[\"occupation\"].mode()\n",
    "# obj_train_df[\"relationship\"].mode()\n",
    "# obj_train_df[\"race\"].mode()\n",
    "# obj_train_df[\"gender\"].mode()\n",
    "# obj_train_df[\"native_country\"].mode()\n",
    "X = X.fillna({\"workclass\": \"Private\",\n",
    "                            \"education\":\"HS-grad\",\n",
    "                            \"marital_status\":\"Married-civ-spouse\",\n",
    "                            \"occupation\": \" Prof-specialty\" ,\n",
    "                            \"relationship\": \"Husband\",\n",
    "                            \"race\": \"White\",\n",
    "                            \"gender\": \"Male\"  ,\n",
    "                            \"native_country\": \"United-States\"\n",
    "            })\n",
    "\n",
    "train_df[train_df.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Done]   Replace all categorical data (data that is in categories, not numbers) with one-hot encoding \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot_encoding_df = pd.get_dummies(X, columns= X.select_dtypes(include=['object']))\n",
    "one_hot_encoding_df = pd.get_dummies(X)\n",
    "one_hot_encoding_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [done] Divide the data into a training and test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(one_hot_encoding_df, y, test_size=0.33)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [done] Run a random forest on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "# my_decisiontree = DecisionTreeClassifier()\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\") \n",
    "clf.fit(X_train, y_train)\n",
    "rand_tree_predict = clf.predict(X_test)\n",
    "\n",
    "print(rand_tree_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [done] 2 pts Compute the accuracy of predictions on test set\n",
    "## Random Forest Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = clf.score(X_train, y_train)\n",
    "acc_test = clf.score(X_test, y_test)\n",
    "print(\"Accuracy on training data:\", acc_train)\n",
    "print(\"Accuracy on test data:\", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_split=2)\n",
    "clf2 = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_split=90)\n",
    "clf1.fit(X_train, y_train)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "acc_min_samples_split_2 = clf1.score(X_test, y_test)\n",
    "acc_min_samples_split_50 = clf2.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy with min split = 2:\", acc_min_samples_split_2)\n",
    "print(\"Accuracy with min split = 100:\", acc_min_samples_split_50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, rand_tree_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pydotplus\n",
    "\n",
    "tree.export_graphviz(clf2, out_file='imgs/tree.dot')\n",
    "\n",
    "! dot -Tpng imgs/tree.dot -o imgs/result.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [done]  gaussian naive bayes on the training set.\n",
    "\n",
    "## gaussian naive bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "gnb_prediction = gnb.predict(X_test)\n",
    "print(gnb_prediction)\n",
    "\n",
    "# score_lr = accuracy_score(y_test, y_predict_logreg)\n",
    "# print(\"Acurracy on Logistic Regression Classifier: \" , score_lr)\n",
    "\n",
    "\n",
    "# y_test_list = list(y_test)\n",
    "# linreg_converted_list_y_test= convert_from_string_to_binary(y_test_list)\n",
    "\n",
    "\n",
    "# linreg_acc_train = linreg.score(X_train, linreg_converted_list_y_train)\n",
    "# linreg_acc_test = linreg.score(X_test, pd.Series(linreg_converted_list_y_test))\n",
    "\n",
    "# print(\"Accuracy on Linear Regression training data:\", linreg_acc_train)\n",
    "# print(\"Accuracy on Linear Regression testing data:\", linreg_acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [done] 2 pts Compute the accuracy of predictions on the test set\n",
    "## Gaussian Naive Bayes  Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_acc_train = gnb.score(X_train, y_train)\n",
    "gnb_acc_test = gnb.score(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training data gaussian naive bayes:\", gnb_acc_train)\n",
    "print(\"Accuracy on test data gaussian naive bayes:\", gnb_acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, gnb_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# [Extra Credit] KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k = 4\n",
    "knn = KNeighborsClassifier(n_neighbors=k) \n",
    "knn.fit(X_train, y_train)\n",
    "knn_predict = knn.predict(X_test)\n",
    "\n",
    "print(knn_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighbors Classifier Acurracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_acc_train = knn.score(X_train, y_train)\n",
    "knn_acc_test = knn.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on training data KNeighbors\", knn_acc_train)\n",
    "print(\"Accuracy on test data KNeighborss:\", knn_acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighbors Classifier Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, knn_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# [Extra Credit]   LINEAR REGRESSION Classifier\n",
    "\n",
    "### Needed to convert to binary for y_train because this classification does not take in strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# score_lr = accuracy_score(y_test, y_predict_logreg)\n",
    "# print(\"Acurracy on Logistic Regression Classifier: \" , score_lr)\n",
    "\n",
    "\n",
    "# y_test_list = list(y_test)\n",
    "# linreg_converted_list_y_test= convert_from_string_to_binary(y_test_list)\n",
    "\n",
    "\n",
    "# linreg_acc_train = linreg.score(X_train, linreg_converted_list_y_train)\n",
    "# linreg_acc_test = linreg.score(X_test, pd.Series(linreg_converted_list_y_test))\n",
    "\n",
    "# print(\"Accuracy on Linear Regression training data:\", linreg_acc_train)\n",
    "# print(\"Accuracy on Linear Regression testing data:\", linreg_acc_test)from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def convert_from_string_to_binary(list_a):\n",
    "    temp_list = []\n",
    "    for item in list_a:\n",
    "        if item == '<=50K':\n",
    "            temp_list.append(0.0)\n",
    "        else:\n",
    "            temp_list.append(1.0)\n",
    "    return temp_list\n",
    "\n",
    "    \n",
    "linreg = LinearRegression()\n",
    "y_train_list = list(y_train)\n",
    "linreg_converted_list_y_train = convert_from_string_to_binary(y_train_list)\n",
    "\n",
    "\n",
    "linreg.fit(X_train, linreg_converted_list_y_train)\n",
    "linreg_prediction = linreg.predict(X_test)\n",
    "print(linreg_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# LINEAR REGRESSION Classifier Acurracy\n",
    "\n",
    "### Needed to convert to binary for y_test because this classification does not take in strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_list = list(y_test)\n",
    "linreg_converted_list_y_test= convert_from_string_to_binary(y_test_list)\n",
    "\n",
    "linreg_acc_train = linreg.score(X_train, linreg_converted_list_y_train)\n",
    "linreg_acc_test = linreg.score(X_test, pd.Series(linreg_converted_list_y_test))\n",
    "\n",
    "print(\"Accuracy on Linear Regression training data:\", linreg_acc_train)\n",
    "print(\"Accuracy on Linear Regression testing data:\", linreg_acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "# [Extra Credit]   Logistic Regression  Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_predict_logreg = logreg.predict(X_test)\n",
    "print(y_predict_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Logistic Regression Classifier Acurracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_acc_train = logreg.score(X_train, y_train)\n",
    "logreg_acc_test = logreg.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy on Logisitc Regression training data:\", logreg_acc_train)\n",
    "print(\"Accuracy on Logisitc Regression testing data:\", logreg_acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Logistic Regression  Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_predict_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DATA DICTIONARY\n",
    " age: continuous.\n",
    "\n",
    " workclass: \n",
    " \n",
    " fnlwgt: continuous.\n",
    " \n",
    " education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    " \n",
    " education-num: continuous.\n",
    " \n",
    " marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    " \n",
    " occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    " \n",
    " relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    " \n",
    " race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    " \n",
    " sex: Female, Male.\n",
    " \n",
    " capital-gain: continuous.\n",
    "\n",
    " capital-loss: continuous.\n",
    "\n",
    " hours-per-week: continuous.\n",
    "\n",
    " native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
